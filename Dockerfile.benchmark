# =============================================================================
# Dockerfile.benchmark - Optimized SQL Throughput Challenge Benchmark Runner
# =============================================================================
# Multi-stage build optimized for minimal image size and security.
# =============================================================================

ARG PYTHON_IMAGE=python:3.12-slim-bookworm

# -----------------------------------------------------------------------------
# Stage 1: Builder - Compile dependencies and install packages
# -----------------------------------------------------------------------------
FROM ${PYTHON_IMAGE} AS builder

# Build tools for native deps (psycopg) + venv setup in one layer
ENV VIRTUAL_ENV=/opt/venv \
    PATH="/opt/venv/bin:$PATH" \
    POETRY_HOME=/opt/poetry \
    POETRY_CACHE_DIR=/root/.cache/pypoetry
RUN apt-get update && apt-get install -y --no-install-recommends \
        build-essential \
        libpq-dev \
    && python -m venv "$VIRTUAL_ENV" \
    && pip install --no-cache-dir --upgrade pip wheel poetry \
    && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*

WORKDIR /build

# Copy dependency spec first for better layer caching
COPY pyproject.toml poetry.lock README.md LICENSE ./
COPY src/ ./src/

# BuildKit poetry cache speeds rebuilds; cache is not baked into the image
RUN --mount=type=cache,target=/root/.cache/pypoetry \
    poetry config virtualenvs.create false \
    && poetry install --only=main --no-interaction --no-ansi --no-root

# Aggressive cleanup to reduce final image size
RUN set -ex && \
    find $VIRTUAL_ENV -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true && \
    find $VIRTUAL_ENV -type f \( -name "*.pyc" -o -name "*.pyo" \) -delete && \
    find $VIRTUAL_ENV -type d \( -name "tests" -o -name "test" -o -name "testing" \) -exec rm -rf {} + 2>/dev/null || true && \
    find $VIRTUAL_ENV -type d \( -name "docs" -o -name "doc" -o -name "examples" -o -name "example" \) -exec rm -rf {} + 2>/dev/null || true && \
    rm -rf $VIRTUAL_ENV/share/doc/* $VIRTUAL_ENV/share/man/* 2>/dev/null || true && \
    find $VIRTUAL_ENV -type f -name "RECORD" -delete && \
    find $VIRTUAL_ENV -type f -name "INSTALLER" -delete && \
    find $VIRTUAL_ENV -type f -name "WHEEL" -delete && \
    find $VIRTUAL_ENV -type f -name "*.so" -exec strip --strip-unneeded {} \; 2>/dev/null || true

# -----------------------------------------------------------------------------
# Stage 2: Runtime - Minimal production image
# -----------------------------------------------------------------------------
FROM ${PYTHON_IMAGE} AS runtime

# Labels for image metadata (OCI standard)
LABEL org.opencontainers.image.title="SQL Benchmark Runner" \
      org.opencontainers.image.description="Benchmarking suite for SQL read strategies" \
    org.opencontainers.image.source="https://github.com/aluiziolira/sql-throughput-challenge" \
      org.opencontainers.image.licenses="MIT"

# Runtime-only dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
        libpq5 \
    && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*

# Non-root user for security
RUN groupadd --gid 1000 benchmark && \
    useradd --uid 1000 --gid benchmark --shell /sbin/nologin --no-create-home benchmark

# Copy venv from builder
ENV VIRTUAL_ENV=/opt/venv \
    PATH="/opt/venv/bin:$PATH"
COPY --from=builder $VIRTUAL_ENV $VIRTUAL_ENV

WORKDIR /app

# Application files
COPY --chown=benchmark:benchmark src/ ./src/
COPY --chown=benchmark:benchmark scripts/ ./scripts/
RUN mkdir -p /app/results && chown -R benchmark:benchmark /app

USER benchmark

# Python/runtime config
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONHASHSEED=42 \
    PYTHONFAULTHANDLER=1 \
    PYTHONPATH=/app \
    DB_HOST=postgres \
    DB_PORT=5432 \
    DB_USER=postgres \
    DB_NAME=throughput_challenge

# Health check to verify Python environment is functional
HEALTHCHECK --interval=30s --timeout=5s --start-period=5s --retries=3 \
    CMD python -c "import src.main" || exit 1

# Default entrypoint runs the benchmark
ENTRYPOINT ["python", "-m", "src.main"]
CMD ["run", "--strategy", "all", "--rows", "100000", "--runs", "5"]
